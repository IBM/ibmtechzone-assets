# -*- coding: utf-8 -*-
"""Prompt evaluation_rouge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xmKUfp4qDIOnxiT4wgt1qwCwakoFtsE8

![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)
# Prompt Notebook - Prompt Lab Notebook v1.0.0
This notebook contains steps and code to demonstrate inferencing of prompts
generated in Prompt Lab in watsonx.ai. It introduces Python API commands
for authentication using API key and prompt inferencing using WML API.

**Note:** Notebook code generated using Prompt Lab will execute successfully.
If code is modified or reordered, there is no guarantee it will successfully execute.
For details, see: [Saving your work in Prompt Lab as a notebook](/docs).

Some familiarity with Python is helpful. This notebook uses Python 3.10.

## Notebook goals
The learning goals of this notebook are:

* Creating an access token from the IBM Cloud personal API key
* Defining a Python class for calling the WML Foundation Model inferencing API
* Using the class to generate output from a provided text input

# Setup

## Inferencing class
This cell defines a class that makes a REST API call to the watsonx Foundation Model
inferencing API that we will use to generate output from the provided input.
The class takes the access token created in the previous step, and uses it to
make a REST API call with input, model id and model parameters. The response
from the API call is returned as the cell output.
"""

import requests

class Prompt:
    def __init__(self, access_token, project_id):
        self.access_token = access_token
        self.project_id = project_id

    def generate(self, input, model_id, parameters):
        wml_url = "https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2023-05-28"
        Headers = {
            "Authorization": "Bearer " + self.access_token,
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        data = {
            "model_id": model_id,
            "input": input,
            "parameters": parameters,
            "project_id": self.project_id
        }
        response = requests.post(wml_url, json=data, headers=Headers)
        if response.status_code == 200:
            return response.json()["results"][0]["generated_text"]
        else:
            return response.text

"""## watsonx API connection
This cell defines the credentials required to work with watsonx API for Foundation
Model inferencing.

**Action:** Provide the IBM Cloud personal API key. For details, see
[documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui).
"""

from ibm_cloud_sdk_core import IAMTokenManager
from ibm_cloud_sdk_core.authenticators import IAMAuthenticator, BearerTokenAuthenticator
import os, getpass

access_token = IAMTokenManager(
    apikey = getpass.getpass("Please enter your api key (hit enter): "),
    url = "https://iam.cloud.ibm.com/identity/token"
).get_token()

"""# Inferencing
This cell demonstrated how we can use the defined class as well as the
created access token to pair it with model id, parameters and input string
to obtain the response from the the selected foundation model.

## Defining the model id
We need to specify model id that will be used for inferencing:
"""

model_id = "meta-llama/llama-2-70b-chat"

"""## Defining the model parameters
We need to provide a set of model parameters that will influence the
result:
"""

parameters = {
    "decoding_method": "sample",
    "max_new_tokens": 200,
    "min_new_tokens": 1,
    "random_seed": 42,
    "temperature": 0.7,
    "top_k": 50,
    "top_p": 1,
    "repetition_penalty": 1
}

"""## Defining the project id
The API requires project id that provides the context for the call. We will obtain
the id from the project in which this notebook runs:
"""

import os

project_id = os.environ["PROJECT_ID"]

"""## Defining the inferencing input
Foundation model inferencing API accepts a natural language input that it will use
to provide the natural language response. The API is sensitive to formatting. Input
structure, presence of training steps (one-shot, two-shot learning etc.), as well
as phrasing all influence the final response and belongs to the emerging discipline of
Prompt Engineering.

Let us provide the input we got from the Prompt Lab:
"""

prompt_input = """<s>[INST] <<SYS>>
Eres un experto en clasificación de reclamos de una operadora telefónica. Solo debes producir output en formato JSON y en lenguaje español.
<</SYS>>
 Debes analizar los inputs y devolver el output en formato JSON siguiendo la estructura de los ejemplos a continuación:

Input:
"some input"
Output:
{{
json output
}}

Input:
{}

Output:
 [/INST]
"""

# a list of input given to prompt as examples
input_list_movil=["list of input given to prompt"]

import os, types
import pandas as pd
from botocore.client import Config
import ibm_boto3
from ibm_watson_machine_learning.foundation_models import Model
from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams
from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes

# @hidden_cell
# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.
# You might want to remove those credentials before you share your notebook.

cos_client = ibm_boto3.client(
    service_name='s3',
    aws_access_key_id='706e420c5ce54bd6b9059205e9b9e13c',
    aws_secret_access_key='2db7f9f28ba798ab8eb2fe9e2170b090c5fcbede19b19167',
    endpoint_url='https://s3.private.br-sao.cloud-object-storage.appdomain.cloud'
)

bucket = 'bv6vavnbxqgd9jbnevltrtfsecezta'
object_key_movil = 'data.csv'


body_movil = cos_client.get_object(Bucket=bucket,Key=object_key_movil)['Body']


df_movil = pd.read_csv(body_movil, sep=";").dropna()

Input_movil=df_movil["INPUT"].astype(str).tolist()

reference_movil=[]

references_movil=df_movil["OUTPUT"].astype(str).tolist()

output_movil=[]
prompt = Prompt(access_token, project_id)

"""## Execution
Let us now use the defined variables to create an instance of the class
we defined previously and get the response from the selected foundation model:
"""

for i in range(len(Input_movil)):
    if(Input_movil[i] not in input_list_movil):
        prompt_text=prompt_input.format(Input_movil[i])
        result=prompt.generate(prompt_text, model_id, parameters)
        output_movil.append(result)
        reference_movil.append(references_movil[i])
#prompt = Prompt(access_token, project_id)
#output.append(result)

print(output_movil)

print(reference_movil)

import json

"""# Next steps
You successfully completed this notebook! You learned how to use
watsonx.ai inferencing API to generate response from the foundation model
based on the provided input, model id and model parameters. Check out the
official watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.

<a id="copyrights"></a>
### Copyrights

Licensed Materials - Copyright © 2023 IBM. This notebook and its source code are released under the terms of the ILAN License.
Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.

**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  

By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href="http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF">License Terms</a>  
"""

! pip install rouge_score

from rouge_score import rouge_scorer
import pandas as pd


# Function to calculate Rouge Score
def calculate_rouge_score(original, prediction):
    scorer = rouge_scorer.RougeScorer(['rougeL'])
    score  = scorer.score(original,prediction)
    return score

def calculate_f1_score(reference, prediction):
    prediction_tokens = prediction.lower().split()
    reference_tokens = reference.lower().split()

    common_tokens = set(prediction_tokens) & set(reference_tokens)

    if len(common_tokens) == 0:
        return 0.0

    precision = len(common_tokens) / len(prediction_tokens)
    recall = len(common_tokens) / len(reference_tokens)

    f1 = (2 * precision * recall) / (precision + recall)
    return f1

def calculate_em_score(reference, prediction):
    return int(prediction.lower() == reference.lower())

import ast
score=[]
score_f1=[]
score_em=[]
for i in range(len(output_movil)):
    if i!=2 and i!=5 and i!=15 and i!=16 and i!=31 and i!=35:
        json_data=ast.literal_eval(reference_movil[i])
        json_data_p=ast.literal_eval(output_movil[i])
        new_json_data={}
        new_json_data['ruta']=json_data['ruta']
        new_json_data['causa_raiz']=json_data['causa_raiz']
        new_json_data_p={}
        new_json_data_p['ruta']=json_data_p['ruta']
        new_json_data_p['causa_raiz']=json_data_p['causa_raiz']
        new_reference=str(new_json_data)
        new_prediction=str(new_json_data_p)
        rouge_score = calculate_rouge_score(new_reference, new_prediction)
        f1_score = calculate_f1_score(new_reference, new_prediction)
        em_score=calculate_em_score(new_reference, new_prediction)
        score.append(rouge_score)
        score_f1.append(f1_score)
        score_em.append(em_score)

import ast
score_rouge_ruta=[]
score_rouge_causa_raiz=[]
score_f1_ruta=[]
score_f1_causa_raiz=[]
for i in range(len(output_movil)):
    if i!=2 and i!=5 and i!=15 and i!=16 and i!=31 and i!=35:
        json_data=ast.literal_eval(reference_movil[i])
        json_data_p=ast.literal_eval(output_movil[i])
        output_ruta=json_data['ruta']
        output_causa_raiz=json_data['causa_raiz']
        predicted_ruta=json_data_p['ruta']
        predicted_causa_raiz=json_data_p['causa_raiz']
        rouge_score_ruta = calculate_rouge_score(output_ruta, predicted_ruta)
        rouge_score_causa_raiz = calculate_rouge_score(output_causa_raiz, predicted_causa_raiz)
        f1_score_ruta = calculate_f1_score(output_ruta, predicted_ruta)
        f1_score_causa_raiz = calculate_f1_score(output_causa_raiz, predicted_causa_raiz)
        score_rouge_ruta.append(rouge_score_ruta)
        score_rouge_causa_raiz.append(rouge_score_causa_raiz)
        score_f1_ruta.append(f1_score_ruta)
        score_f1_causa_raiz.append(f1_score_causa_raiz)

sum_p=0
sum_r=0
sum_f=0
for i in range(len(score_rouge_ruta)):
    sum_p=sum_p+score_rouge_ruta[i]["rougeL"].precision
    sum_r=sum_r+score_rouge_ruta[i]["rougeL"].recall
    sum_f=sum_f+score_rouge_ruta[i]["rougeL"].fmeasure
print("rouge_score for ruta:")
print(sum_p/len(score_rouge_ruta), sum_r/len(score_rouge_ruta),sum_f/len(score_rouge_ruta))

sum_p=0
sum_r=0
sum_f=0
for i in range(len(score_rouge_causa_raiz)):
    sum_p=sum_p+score_rouge_causa_raiz[i]["rougeL"].precision
    sum_r=sum_r+score_rouge_causa_raiz[i]["rougeL"].recall
    sum_f=sum_f+score_rouge_causa_raiz[i]["rougeL"].fmeasure
print("rouge_score for causa_raiz:")
print(sum_p/len(score_rouge_causa_raiz), sum_r/len(score_rouge_causa_raiz),sum_f/len(score_rouge_causa_raiz))

sum_f1=0
for i in range(len(score_f1_ruta)):
    sum_f1=sum_f1+score_f1_ruta[i]
print("ruta f1 score is:" + str(sum_f1/len(score_f1_ruta)))

sum_f1=0
for i in range(len(score_f1_causa_raiz)):
    sum_f1=sum_f1+score_f1_causa_raiz[i]
print("causa_raiz f1 score is:" + str(sum_f1/len(score_f1_causa_raiz)))

sum_p=0
sum_r=0
sum_f=0
for i in range(len(score)):
    sum_p=sum_p+score[i]["rougeL"].precision
    sum_r=sum_r+score[i]["rougeL"].recall
    sum_f=sum_f+score[i]["rougeL"].fmeasure
print("combined rouge score for ruta and causa_raiz")
print(sum_p/len(score), sum_r/len(score),sum_f/len(score))

sum_f1=0
for i in range(len(score_f1)):
    sum_f1=sum_f1+score_f1[i]
print("combined f1 score for ruta and causa_raiz:" + str(sum_f1/len(score_f1)))

sum_em=0
for i in range(len(score_em)):
    sum_em=sum_em+score_em[i]
print("combined em score for ruta and causa_raiz:" + str(sum_em/len(score_em)))