{"id":"hhzyutyelz","title":"Text streaming with watsonx LLMs","documentationURL":"https://ibm.box.com/s/lue49aerkaps3l7pkhlypcwfiitdizrf","author":"Naveen Narayan, Aravind Krishnan B","categoryId":1,"description":"Text streaming with watsonx LLMs\n\nThis allows real-time streaming of LLM outputs as they are generated, eliminating the need to wait for the entire content to be produced. ","typeId":1,"type":"python","fileName":"wx_output_streaming_backend.py","source":"git","assetURL":"https://github.ibm.com/Naveen-Narayan1/text-streaming-wx","userId":"a2f5de35-6631-46c6-8ac3-2b385aa48170","preRequisites":{"fields":[],"requiredFields":[[]],"installDependencyCommands":[""]},"createdTimestamp":1725871917267,"updatedTimestamp":1725871917267}