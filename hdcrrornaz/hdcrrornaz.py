# -*- coding: utf-8 -*-
"""Visualizations_pyvis _updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18DE1MU-Eynt4LwqH-YZngIpj8YIgcSPZ
"""

!pip install pyvis

from pyvis.network import Network

# Load JSON data from file
import json
with open('ontology.json', 'r') as file:
    ontology = json.load(file)

# creating graph from ontology
def save_ontology_network_html(kb,df, filename="network.html"):
    # create network
    net = Network(directed=True, width="1000px", height="1000px", bgcolor="#eeeeee",cdn_resources='in_line')

    # nodes
    color_entity = ["#3da831","#00ff1e", "#20B2AA", "#dd4b39", "#00bfff", "#ffc0cb", "#7B68EE", "#9a31a8", "#3155a8", "#DB7093","#00ffff","#7FFFD4","#9ACD32","#808000","#BC8F8F","#FF00FF","#BDB76B","#FFD700","#FFA07A","#FA8072"]
    columns=df.columns
    index={}
    color={}
    i=0
    j=0
    print(len(columns))
    for c in columns:
      index[c]=i
      color[c]=color_entity[j]
      j=j+1
      i=i+len(df[c])
    for r in kb:
        net.add_node(str(r["Source"]), shape="dot", color=color[r["Source"]])
        net.add_node(str(r["Target"]), shape="dot", color=color[r["Target"]])
        net.add_edge(str(r["Source"]), str(r["Target"]),
                    title=r["Relationship"], label=r["Relationship"])


    # save network
    net.repulsion(
        node_distance=200,
        central_gravity=0.2,
        spring_length=200,
        spring_strength=0.05,
        damping=0.09
    )
    net.set_edge_smooth('dynamic')
    net.show(filename,notebook=False)

import warnings
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np

#print(ontology)

#read csv file
#from pradumns notebook
df = pd.read_excel("monday.xlsx")
df.rename(columns={'Name':'Pillar_Name'}, inplace=True)
df.columns = df.columns.to_series().apply(lambda x: x.replace('Pilot', 'Project').replace(' ', '_'))
# Convert column names to lowercase
df.columns = map(str.lower, df.columns)
# Convert string values in rows to lowercase
df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)
df = df[~df['pillar_name'].isin(['Not Found/No Entry #!!  #!!', np.nan])]
df = df[~df['project_name'].isin(['Not Found/No Entry #!!  #!!', np.nan])]
df.replace(['Not Found/No Entry #!!  #!!', 'Not Found/No Entry','not found/no entry #!! #!!','not found/no entry #!!  #!!'], 'No Information Available', inplace=True)
df.fillna('No Information Available', inplace=True)
df = df.reset_index(drop=True)
df.head(3)

import IPython
filename = "ontology.html"
save_ontology_network_html(ontology, df,filename=filename)
#IPython.display.HTML(filename=filename)

IPython.display.HTML(filename=filename)

def save_network1_html(kb,df, filename="network.html"):
    # create network
    net = Network(directed=True, width="2000px", height="2000px", bgcolor="#eeeeee",cdn_resources='in_line')
    net1 = Network(directed=False, width="2000px", height="2000px", bgcolor="#eeeeee",cdn_resources='in_line')
    # nodes
    color_entity = ["#3da831","#00ff1e", "#20B2AA", "#dd4b39", "#00bfff", "#ffc0cb", "#7B68EE", "#9a31a8", "#3155a8", "#DB7093","#00ffff","#7FFFD4","#9ACD32","#808000","#BC8F8F","#FF00FF","#BDB76B","#FFD700","#FFA07A","#FA8072"]
    columns=df.columns
    index={}
    color={}
    node_degrees={}
    new_node={}
    new_kb=[]
    i=0
    j=0
    #print(len(columns))
    for c in columns:
      index[c]=i
      color[c]=color_entity[j]
      j=j+1
      i=i+len(df[c])
    #print(color)
    for r in kb:
      #print(len(df[r["Source"]]))
      for k in range(0,len(df[r["Source"]])):
        #print(df[r["Target"]][k])
        net.add_node(str(df[r["Source"]][k]), shape="dot", color=color[r["Source"]])
        #nodes_degree[str(df[r["Source"]][k])]=0
        net.add_node(str(df[r["Target"]][k]), shape="dot", color=color[r["Target"]])
        net.add_edge(str(df[r["Source"]][k]), str(df[r["Target"]][k]),
                    title=r["Relationship"], label=r["Relationship"])
    # Function to count edges between two nodes
    def count_edges_between_nodes(node1, node2):
        edge_count = 0
        edge1="nan"
        for edge in net.edges:
            #print(edge['from']==node1,edge['to'])
            if (edge['from'] == node1 and edge['to'] == node2) or (edge['from'] == node2 and edge['to'] == node1):
                edge1=edge
                edge_count += 1
        #print(edge)
        return edge_count,edge1

    # Example: Count edges between nodes 1 and 3
    for i in range(len(net.nodes)-1):
      for j in range(i+1,len(net.nodes)):
          #Sprint(net.nodes[i])
          edge_count,edge = count_edges_between_nodes(net.nodes[i]["id"], net.nodes[j]["id"])
          if(edge_count>0):
            new_node["Source"]=str(net.nodes[i]["id"])
            new_node["Target"]=str(net.nodes[j]["id"])
            new_node["Relationship"]=edge["label"]
            new_node["weight"]=edge_count
            new_node["color_s"]=net.nodes[i]["color"]
            new_node["color_t"]=net.nodes[j]["color"]
            #print(new_node)
            #print("/n")
            new_kb.append(new_node)
            new_node={}
    #print(new_kb)
    for r in new_kb:
      #print(df[r["Target"]][k])
      net1.add_node(r["Source"], shape="dot", color=r["color_s"])
        #nodes_degree[str(df[r["Source"]][k])]=0
      net1.add_node(r["Target"], shape="dot", color=r["color_t"])
      net1.add_edge(r["Source"], r["Target"], value=r["weight"],
                  title=r["Relationship"], label=r["Relationship"])



    # save network
    net1.repulsion(
        node_distance=200,
        central_gravity=0.2,
        spring_length=200,
        spring_strength=0.05,
        damping=0.09
    )
    net1.set_edge_smooth('dynamic')
    net1.show(filename,notebook=False)

filename = "monday_data_updated_all.html"
save_network1_html(ontology,df,filename=filename)
#IPython.display.HTML(filename=filename)

IPython.display.HTML(filename=filename)

# Load JSON data from file
import json
with open('/content/triplets_with_source.json', 'r') as file:
    triplets = json.load(file)

#visualisation of graphs made from unstructured data
def save_triplets_network_html(kb, filename="network.html"):
    # create network
    net = Network(directed=True, width="2000px", height="2000px", bgcolor="#eeeeee",cdn_resources='in_line')

    # nodes
    color_entity = ["#3da831","#00ff1e", "#20B2AA", "#dd4b39", "#00bfff", "#ffc0cb", "#7B68EE", "#9a31a8", "#3155a8", "#DB7093","#00ffff","#7FFFD4","#9ACD32","#808000","#BC8F8F","#FF00FF","#BDB76B","#FFD700","#FFA07A","#FA8072"]
    #index={}
    color={
    "operation": "#ff0000",
    "Parameter": "#ff4500",
    "returnType": "#ff8c00",
    "prerequisites": "#ffd700",
    "Legal System": "#ffff00",
    "Population Census": "#adff2f",
    "City": "#7fff00",
    "module": "#32cd32",
    "Requirement": "#00ff00",
    "Religious Institution": "#228b22",
    "Authentication": "#008000",
    "Module": "#006400",
    "modules": "#8fbc8f",
    "Geographical Feature": "#20b2aa",
    "supportedProducts": "#40e0d0",
    "Changelog": "#7fffd4",
    "parameter": "#00ced1",
    "Enum": "#1e90ff",
    "Attribute": "#6495ed",
    "foundationModels": "#4169e1",
    "Machine Learning Framework": "#0000ff",
    "value": "#4b0082",
    "ReturnType": "#800080",
    "Government System": "#ee82ee",
    "ModelInference": "#ff00ff",
    "notebook": "#ff1493",
    "autoAI": "#ff69b4",
    "source": "#db7093",
    "Historical Event": "#b03060",
    "Method": "#c71585",
    "type": "#d02090",
    "federatedLearning": "#ff1493",
    "ModelType": "#ff4500",
    "object": "#ff6347",
    "core": "#ffa07a",
    "Sport": "#fa8072",
    "Software": "#f08080",
    "Library": "#cd5c5c",
    "environment": "#f4a460",
    "parameters": "#daa520",
    "Product": "#b8860b",
    "Language": "#d2691e",
    "Class": "#8b4513",
    "Product Offering": "#a0522d",
    "example": "#a52a2a",
    "Country": "#800000"
}
    i=0
    j=0
    keys=[]
    keys_unique=[]
    keys_unique1=[]

    for r in kb:
      for n in r.keys():
        keys.append(n)
      #color[r["Product"]]=color_entity[j]
    keys_unique=set(keys)
    for h in keys_unique:
      if h != "predicate":
        keys_unique1.append(h)
    #print(keys_unique1)
      #i=i+len(df[c])
    #for m in keys.distinct():
      #color[m]=color_entity[j]
      #j=j+1
    count=0
    for r in  kb:
        triplet=[]
        for t in r.keys():
          triplet.append(t)
        #print(color[triplet[0]])
        net.add_node(str(r[triplet[0]]), shape="dot", color=color_entity[0])
        net.add_node(str(r[triplet[2]]), shape="dot", color=color_entity[0])
        net.add_edge(str(r[triplet[0]]), str(r[triplet[2]]),
                    title=r[triplet[1]], label=r[triplet[1]])
        count=count+1


    # save network
    net.repulsion(
         node_distance=100,
         central_gravity=0.2,
         spring_length=100,
         spring_strength=0.05,
         damping=0.09
     )
    net.set_edge_smooth('dynamic')
    net.show(filename,notebook=False)

filename = "triples_data.html"
save_triplets_network_html(triplets,filename=filename)
#IPython.display.HTML(filename=filename)

IPython.display.HTML(filename=filename)