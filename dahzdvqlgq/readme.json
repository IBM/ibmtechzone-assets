{"id":"dahzdvqlgq","title":"WatsonX AI Image and Text Interaction","documentationURL":"https://github.ibm.com/Soumyajit-Bera/Mutlimodal-Testing","author":"Soumyajit Bera","categoryId":1,"description":"Welcome to LLaVA-Testing, where we leverage IBM WatsonX's capabilities to interact with images and text input dynamically. This project utilizes LLaVA (Local Large Vision Assistant) for image and text-based responses using IBM Watson models. Enter text prompts and image inputs at runtime to generate detailed responses. Let’s dive into how to set up and use this project!\n\nFeaturesl:-\n\nDynamic Input Handling: Input your API Key, Project ID, Text Description, and Image URL or Path directly at runtime—no need for hardcoded configurations.\nAuto Image Processing: Automatically resize and encode images to base64 format, whether from a URL or local path.\nInteractive Image Display: Visualize your images directly within the output for easy reference.\nCustomizable Prompts: Tailor the interaction with both images and text input, and receive rich responses from WatsonX’s advanced LLaVA model.","typeId":1,"type":"python","fileName":"dahzdvqlgq.py","source":"local","assetURL":"","userId":"8a5ede2a-2e2a-4f3c-a3de-48a9190f37be","preRequisites":{"fields":[],"requiredFields":[[]],"installDependencyCommands":["appnope==0.1.4 asttokens==2.4.1 certifi==2024.8.30 charset-normalizer==3.3.2 comm==0.2.2 debugpy==1.8.6 decorator==5.1.1 executing==2.1.0 idna==3.10 ipykernel==6.29.5 ipython==8.27.0 jedi==0.19.1 jupyter_client==8.6.3 jupyter_core==5.7.2 matplotlib-inline==0.1.7 nest-asyncio==1.6.0 packaging==24.1 parso==0.8.4 pexpect==4.9.0 pillow==10.4.0 platformdirs==4.3.6 prompt_toolkit==3.0.48 psutil==6.0.0 ptyprocess==0.7.0 pure_eval==0.2.3 Pygments==2.18.0 python-dateutil==2.9.0.post0 python-dotenv==1.0.1 pyzmq==26.2.0 requests==2.32.3 six==1.16.0 stack-data==0.6.3 tornado==6.4.1 traitlets==5.14.3 urllib3==2.2.3 wcwidth==0.2.13"]},"createdTimestamp":1727420291877,"updatedTimestamp":1727420291877}