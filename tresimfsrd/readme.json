{"id":"tresimfsrd","title":"Semantic chunking","documentationURL":"readme.md","author":"Soumya Sv","categoryId":1,"description":"This Python script provides an automated solution for performing semantic chunking on large text documents and saving the resulting chunks into a CSV file. The asset utilizes a multilingual tokenizer and a semantic text splitter to divide the input text into chunks based on a token limit defined by the user or configuration","typeId":1,"type":"python","fileName":"tresimfsrd.py","source":"local","assetURL":"","userId":"b7fcb093-5d84-4181-9215-79957ccfa128","preRequisites":{"fields":[],"requiredFields":[[]],"installDependencyCommands":["pip install pandas tokenizers semantic_text_splitter "]},"createdTimestamp":1727245690330,"updatedTimestamp":1727245690330}